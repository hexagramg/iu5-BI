{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "lab2_task2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hexagramg/iu5-BI/blob/master/lab/lab2_task2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-fA7WvTx3Py",
        "colab_type": "code",
        "outputId": "adf702a5-c070-46f7-e55e-d49a92063eb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "!pip install git+https://github.com/google-research/tf-slim"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/google-research/tf-slim\n",
            "  Cloning https://github.com/google-research/tf-slim to /tmp/pip-req-build-le5_kkdj\n",
            "  Running command git clone -q https://github.com/google-research/tf-slim /tmp/pip-req-build-le5_kkdj\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf-slim==1.1) (0.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py>=0.2.2->tf-slim==1.1) (1.12.0)\n",
            "Building wheels for collected packages: tf-slim\n",
            "  Building wheel for tf-slim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tf-slim: filename=tf_slim-1.1-cp36-none-any.whl size=357897 sha256=e05d7352dd604ff4a7478abbc855f31e1bced1a3a6e05c4483a42c5d5e0224f1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-rsh9pk8k/wheels/bb/98/dc/eba6500d756d16f6ff371b39ed733d26cec1b0b0085e1cb0df\n",
            "Successfully built tf-slim\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "w-DAcItGxiWg",
        "colab_type": "code",
        "outputId": "c8b3cc14-9df5-49bb-bcb8-9c409b40bd9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "import tf_slim as slim\n",
        "import numpy as np\n",
        "import gym\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "tf.disable_v2_behavior()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cDovvqn5GQc",
        "colab_type": "text"
      },
      "source": [
        "Загрузим необходимое по условию окружение:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "tP5rTkuZxiWl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = gym.make('CartPole-v0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Pk6NhbS-xiWq",
        "colab_type": "text"
      },
      "source": [
        "Напишем функцию, подсчитывающую награду:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "5DGLgOVUxiWr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gamma = 0.99\n",
        "\n",
        "def discount_rewards(r):\n",
        "  discounted_r = np.zeros_like(r)\n",
        "  running_add = 0\n",
        "  for t in reversed(range(0, r.size)):\n",
        "    running_add = running_add * gamma + r[t]\n",
        "    discounted_r[t] = running_add\n",
        "  return discounted_r"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkoAreIz8nmb",
        "colab_type": "text"
      },
      "source": [
        "Определим класс агента, который будет работать в описанной выше среде."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "lMG7yq85xiWu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class agent():\n",
        "  def __init__(self, lr, s_size, a_size, h_size):\n",
        "    self.state_in= tf.placeholder(shape=[None, s_size], dtype=tf.float32)\n",
        "    hidden = slim.fully_connected(self.state_in, h_size, biases_initializer=None, activation_fn=tf.nn.relu)\n",
        "    self.output = slim.fully_connected(hidden, a_size, activation_fn=tf.nn.softmax, biases_initializer=None)\n",
        "    self.chosen_action = tf.argmax(self.output, 1)\n",
        "\n",
        "    self.reward_holder = tf.placeholder(shape=[None], dtype=tf.float32)\n",
        "    self.action_holder = tf.placeholder(shape=[None], dtype=tf.int32)\n",
        "\n",
        "    self.indexes = tf.range(0, tf.shape(self.output)[0]) * tf.shape(self.output)[1] + self.action_holder\n",
        "    self.responsible_outputs = tf.gather(tf.reshape(self.output, [-1]), self.indexes)\n",
        "\n",
        "    self.loss = -tf.reduce_mean(tf.log(self.responsible_outputs) * self.reward_holder)\n",
        "\n",
        "    tvars = tf.trainable_variables()\n",
        "    self.gradient_holders = []\n",
        "    for idx,var in enumerate(tvars):\n",
        "      placeholder = tf.placeholder(tf.float32,name=str(idx) + \"_holder\")\n",
        "      self.gradient_holders.append(placeholder)\n",
        "\n",
        "    self.gradients = tf.gradients(self.loss, tvars)\n",
        "\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
        "    self.update_batch = optimizer.apply_gradients(zip(self.gradient_holders, tvars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "sExFQN3LxiWx",
        "colab_type": "text"
      },
      "source": [
        "Обучаем агента:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "1Y06XJnexiWy",
        "colab_type": "code",
        "outputId": "c2275216-2ec7-4391-c258-d1ecad89ed9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        }
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "myAgent = agent(lr=1e-2, s_size=4, a_size=2, h_size=8)\n",
        "\n",
        "total_episodes = 5000\n",
        "max_ep = 500\n",
        "update_frequency = 5\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  i = 0\n",
        "  total_reward = []\n",
        "  total_length = []\n",
        "      \n",
        "  gradBuffer = sess.run(tf.trainable_variables())\n",
        "  for ix,grad in enumerate(gradBuffer):\n",
        "    gradBuffer[ix] = grad * 0\n",
        "\n",
        "  while i < total_episodes:\n",
        "    s = env.reset()\n",
        "    running_reward = 0\n",
        "    ep_history = []\n",
        "    for j in range(max_ep):\n",
        "      a_dist = sess.run(myAgent.output,feed_dict={myAgent.state_in:[s]})\n",
        "      a = np.random.choice(a_dist[0],p=a_dist[0])\n",
        "      a = np.argmax(a_dist == a)\n",
        "\n",
        "      s1, r, done, _ = env.step(a)\n",
        "      ep_history.append([s, a, r, s1])\n",
        "      s = s1\n",
        "      running_reward += r\n",
        "      if done == True:\n",
        "        ep_history = np.array(ep_history)\n",
        "        ep_history[:,2] = discount_rewards(ep_history[:,2])\n",
        "        feed_dict = {\n",
        "            myAgent.reward_holder: ep_history[:,2],\n",
        "            myAgent.action_holder: ep_history[:,1],\n",
        "            myAgent.state_in:      np.vstack(ep_history[:,0])\n",
        "          }\n",
        "        grads = sess.run(myAgent.gradients, feed_dict=feed_dict)\n",
        "        for idx,grad in enumerate(grads):\n",
        "          gradBuffer[idx] += grad\n",
        "\n",
        "        if i % update_frequency == 0 and i != 0:\n",
        "          feed_dict= dictionary = dict(zip(myAgent.gradient_holders, gradBuffer))\n",
        "          _ = sess.run(myAgent.update_batch, feed_dict=feed_dict)\n",
        "          for ix,grad in enumerate(gradBuffer):\n",
        "            gradBuffer[ix] = grad * 0\n",
        "\n",
        "        total_reward.append(running_reward)\n",
        "        total_length.append(j)\n",
        "        break\n",
        "\n",
        "    if i % 100 == 0:\n",
        "      print(f\"Эпизод {i} средняя награда {np.mean(total_reward[-100:])}, осталось {total_episodes - i}\")\n",
        "    i += 1"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Эпизод 0 средняя награда 19.0, осталось 5000\n",
            "Эпизод 100 средняя награда 23.85, осталось 4900\n",
            "Эпизод 200 средняя награда 33.95, осталось 4800\n",
            "Эпизод 300 средняя награда 45.64, осталось 4700\n",
            "Эпизод 400 средняя награда 52.17, осталось 4600\n",
            "Эпизод 500 средняя награда 56.59, осталось 4500\n",
            "Эпизод 600 средняя награда 64.16, осталось 4400\n",
            "Эпизод 700 средняя награда 95.82, осталось 4300\n",
            "Эпизод 800 средняя награда 124.5, осталось 4200\n",
            "Эпизод 900 средняя награда 142.51, осталось 4100\n",
            "Эпизод 1000 средняя награда 149.13, осталось 4000\n",
            "Эпизод 1100 средняя награда 137.28, осталось 3900\n",
            "Эпизод 1200 средняя награда 147.8, осталось 3800\n",
            "Эпизод 1300 средняя награда 175.09, осталось 3700\n",
            "Эпизод 1400 средняя награда 191.64, осталось 3600\n",
            "Эпизод 1500 средняя награда 199.07, осталось 3500\n",
            "Эпизод 1600 средняя награда 198.72, осталось 3400\n",
            "Эпизод 1700 средняя награда 199.75, осталось 3300\n",
            "Эпизод 1800 средняя награда 193.42, осталось 3200\n",
            "Эпизод 1900 средняя награда 194.3, осталось 3100\n",
            "Эпизод 2000 средняя награда 199.6, осталось 3000\n",
            "Эпизод 2100 средняя награда 191.12, осталось 2900\n",
            "Эпизод 2200 средняя награда 187.84, осталось 2800\n",
            "Эпизод 2300 средняя награда 195.01, осталось 2700\n",
            "Эпизод 2400 средняя награда 194.62, осталось 2600\n",
            "Эпизод 2500 средняя награда 199.33, осталось 2500\n",
            "Эпизод 2600 средняя награда 200.0, осталось 2400\n",
            "Эпизод 2700 средняя награда 199.85, осталось 2300\n",
            "Эпизод 2800 средняя награда 199.6, осталось 2200\n",
            "Эпизод 2900 средняя награда 199.62, осталось 2100\n",
            "Эпизод 3000 средняя награда 200.0, осталось 2000\n",
            "Эпизод 3100 средняя награда 199.89, осталось 1900\n",
            "Эпизод 3200 средняя награда 199.94, осталось 1800\n",
            "Эпизод 3300 средняя награда 200.0, осталось 1700\n",
            "Эпизод 3400 средняя награда 200.0, осталось 1600\n",
            "Эпизод 3500 средняя награда 200.0, осталось 1500\n",
            "Эпизод 3600 средняя награда 200.0, осталось 1400\n",
            "Эпизод 3700 средняя награда 199.96, осталось 1300\n",
            "Эпизод 3800 средняя награда 198.15, осталось 1200\n",
            "Эпизод 3900 средняя награда 198.83, осталось 1100\n",
            "Эпизод 4000 средняя награда 199.4, осталось 1000\n",
            "Эпизод 4100 средняя награда 196.07, осталось 900\n",
            "Эпизод 4200 средняя награда 195.17, осталось 800\n",
            "Эпизод 4300 средняя награда 199.2, осталось 700\n",
            "Эпизод 4400 средняя награда 198.07, осталось 600\n",
            "Эпизод 4500 средняя награда 198.76, осталось 500\n",
            "Эпизод 4600 средняя награда 200.0, осталось 400\n",
            "Эпизод 4700 средняя награда 199.27, осталось 300\n",
            "Эпизод 4800 средняя награда 199.04, осталось 200\n",
            "Эпизод 4900 средняя награда 199.87, осталось 100\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}